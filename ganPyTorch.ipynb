{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01f30f2",
   "metadata": {},
   "source": [
    "# 0x05. Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480912",
   "metadata": {},
   "source": [
    "![descmeme](https://cs236g.stanford.edu/memes/c1w3/mode_collapse_pained_harold.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de20d85",
   "metadata": {},
   "source": [
    "## Resources\n",
    "### Read or watch:\n",
    "[NYU Spring 2020 Week 9 Lecture on GANs](https://www.youtube.com/watch?v=Pgct8PKV7iw&t=5433s)\n",
    "\n",
    "[Dive into Deep Learning: Chapter 17. GANs](https://d2l.ai/chapter_generative-adversarial-networks/gan.html)\n",
    "\n",
    "[A Friendly Introduction to Generative Adversarial Networks (GANs)](https://www.youtube.com/watch?v=8L11aMN5KY8)\n",
    "\n",
    "[Googleâ€™s GAN course](https://developers.google.com/machine-learning/gan)\n",
    "\n",
    "[MIT 6.S191: Deep Generative Modeling - GANs](https://www.youtube.com/watch?v=yFBFl1cLYx8&t=1880s)\n",
    "\n",
    "[Understanding Generative Adversarial Networks](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)\n",
    "\n",
    "[Stanford Graduate Course CS 236: Generative Adversarial Networks](https://cs236g.stanford.edu/)\n",
    "\n",
    "[Thispersondoesnotexist.com](https://thispersondoesnotexist.com/)\n",
    "\n",
    "[Facebook Research Article on PyTorch](https://research.fb.com/publications/pytorch-an-imperative-style-high-performance-deep-learning-library/)\n",
    "\n",
    "[PyTorch Installation Instructions](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "[PyTorch Quick Start Guide](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "[*Recursive Link to Notebook](https://github.com/romxero/holberton_sauce/blob/main/ganPyTorch.ipynb) \n",
    "\n",
    "### The other links \n",
    "[PyTorch NN Class Documentation](https://pytorch.org/docs/stable/nn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53467ab6",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "* What is a generator?\n",
    "* What is a discriminator?\n",
    "* What is the minimax loss? modified minimax loss? wasserstein loss?\n",
    "* How do you train a GAN?\n",
    "* What are the use cases for GANs?\n",
    "* What are the shortcoming of GANs?\n",
    "* What is Energy based learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007da7e2",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "\n",
    "This course is designed to use a novel unsupervised learning technique where a learning model creates generates new data sets that are judged on its authenticity of another learning model.\n",
    "\n",
    "Students are introduced to the concepts and are tasked with making a simple machine learning model with the MINST data set and PyTorch to create the model and train the neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e4c32",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### GANs\n",
    "\n",
    "There is more to machine learning than just solving discriminative tasks (d2l.ai, 2021). Generative adversarial networks provide a way to learn deep representations without extensively labeled training data (ieee, 2014). The generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency (Goodfellow. et al, 2014). They can be characterized by training a pair of net works in competition with each other (IEEE, 2014). One big trend over the last three years has been the application of discriminative deep nets to overcome challenges in problems that we do not generally think of as supervised learning problems (d2l.ai, 2021). \n",
    "\n",
    "GANs are a type of neural network used for unsupervised machine learning (NYU, 2021). They are comprised of two adversarial modules: generator and cost networks (NYU, 2021). \n",
    "\n",
    "These modules compete with each other such that the cost network tries to filter fake examples while the generator tries to trick this filter by creating realistic examples x^\\vect{\\hat{x}}x^ (NYU, 2021). Through this competition, the model learns a generator that creates realistic data (NYU, 2021). They can be used in tasks such as future predictions or for generating images after being trained on a particular dataset (NYU, 2021).\n",
    "\n",
    "The forger, known in the GAN literature as the generator, ,G creates forgeries, with the aim of making realistic images. The expert, known as the discriminator, ,D receives both forgeries and real (authentic) images, and aims to tell them apart (see Figure 1). Both are trained simultaneously, and in competition with each other (IEEE, 2021).\n",
    "\n",
    "### Pytorch\n",
    "#### Modify below, since it came from wikipedia\n",
    "Torch is an open-source machine learning library, a scientific computing framework, and a script language based on the Lua programming language.[3] It provides a wide range of algorithms for deep learning, and uses the scripting language LuaJIT, and an underlying C implementation. It was created at IDIAP at EPFL. As of 2018, Torch is no longer in active development.[4] However PyTorch, which is based on the Torch library, is actively developed as of June 2021.[5] \n",
    "\n",
    "You will notice that we are using PyTorch for this project. PyTorch is another open source deep learning library. It was initially based on the Torch but is now primarily developed by Facebook's AI Research lab. Facebook also updated and merged the Caffe deep learning framework into PyTorch also. \n",
    "\n",
    "It is an optimized library, based on the tensor representations, for deep learning using GPUs and CPUs.\n",
    "\n",
    "PyTorch is very similar to TensorFlow. Pytorch and Tensorflow are by far two of the most popular frameworks for Deep Learning (https://towardsdatascience.com/pytorch-vs-tensorflow-in-2020-fe237862fae1). It has gained significant popularity in recent years due to its; ease of use, rapid prototyping, and speed.\n",
    "\n",
    "The two frameworks had a lot of major differences in terms of design, paradigm, syntax etc till some time back, but they have since evolved a lot, both have picked up good features from each other and are no longer that different (https://towardsdatascience.com/pytorch-vs-tensorflow-in-2020-fe237862fae1).\n",
    "\n",
    "A number of deep learning software has been built using PyTorch; its used internally at Facebook (Meta), Tesla's Autopilot uses PyTorch, Uber's Pyro tool, and others.\n",
    "\n",
    "It is currently as popular as TensorFlow in academic papers being published, and its gaining popularity in Google searches as well:\n",
    "![PyTorch started gaining on Tensorflow in 2019](https://qph.fs.quoracdn.net/main-qimg-aab6d9ab110d815b7365ee153acf625a)\n",
    "*RISElab is a AI lab at UC Berkeley*\n",
    "\n",
    "![Google Search Trends of Tensorflow vs PyTorch](https://miro.medium.com/max/744/1*IsaBkifkc5P7ihRA8IKQ8Q.png)\n",
    "\n",
    "![Google Search Trends of Tensorflow vs PyTorch 2](https://miro.medium.com/max/2000/1*e7fGJaWE_P6x500Obq8_Pw.png)\n",
    "\n",
    "![Google Search Trends of Tensorflow vs PyTorch 3](https://dezyre.gumlet.net/images/blog/PyTorch+vs+TensorFlow+2021-A+Head-to-Head+Comparison/PyTorch+vs+TensorFlow.png?w=1100&dpr=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b96d7e",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "### General\n",
    "\n",
    "* Allowed editors: vi, vim, emacs\n",
    "* All your files will be interpreted/compiled on Ubuntu (version 18.04 LTS or greater) using Python3 (version 3.6 or greater)\n",
    "* Your files will be executed with numpy (version 1.19) and PyTorch (version 1.10)\n",
    "* All your files should end with a new line\n",
    "* The first line of all your files should be exactly #!/usr/bin/env python3\n",
    "* A README.md file, at the root of the folder of the project, is mandatory\n",
    "* Your code should use the pycodestyle style (version 2.4)\n",
    "* #########################REDO_BELOW################################################\n",
    "* All your modules should have documentation (python3 -c 'print(__import__(\"my_module\").__doc__)')\n",
    "* All your classes should have documentation (python3 -c 'print(__import__(\"my_module\").MyClass.__doc__)')\n",
    "* All your functions (inside and outside a class) should have documentation (python3 -c 'print(__import__(\"my_module\").my_function.__doc__)' and python3 -c 'print(__import__(\"my_module\").MyClass.my_function.__doc__)')\n",
    "    Unless otherwise noted, you are not allowed to import any module except import tensorflow as tf and import numpy as np, as needed\n",
    "    All your files must be executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742893ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28074c8f",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520e93e",
   "metadata": {},
   "source": [
    "###  0. Generator \n",
    "* Write a subclass that defines the generator: \n",
    "    class generator(nn.Module):\n",
    "* Make sure you define the forward function inside of the class\n",
    "    def forward(self, x):\n",
    "* Z is a torch.tensor containing the input to the generator network\n",
    "* The network should have two layers:\n",
    "    the first layer should have 128 nodes and use relu activation with name \n",
    "    the second layer should have 784 nodes and use a sigmoid activation with name layer_2\n",
    "* All variables in the network should have the scope generator with reuse=tf.AUTO_REUSE\n",
    "* Returns X, a tf.tensor containing the generated image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4507f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#first lets set up our devices and data type\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\") # This executes all calculations on the CPU\n",
    "#create a tensor type\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edcec81",
   "metadata": {},
   "source": [
    "### 1. Discriminator\n",
    "\n",
    "* Write a subclass that defines the generator: \n",
    "    class discriminator(nn.Module):\n",
    "* Make sure you define the forward function inside of the class\n",
    "    def forward(self, x):\n",
    "    \n",
    "Write a function def discriminator(X): that creates a discriminator network for MNIST digits:\n",
    "\n",
    "    X is a tf.tensor containing the input to the discriminator network\n",
    "    The network should have two layers:\n",
    "        the first layer should have 128 nodes and use relu activation with name layer_1\n",
    "        the second layer should have 1 node and use a sigmoid activation with name layer_2\n",
    "    All variables in the network should have the scope discriminator with reuse=tf.AUTO_REUSE\n",
    "    Returns Y, a tf.tensor containing the classification made by the discriminator\n",
    "\n",
    "Repo:\n",
    "\n",
    "    GitHub repository: holbertonschool-machine_learning\n",
    "    Directory: unsupervised_learning/0x05-GANs\n",
    "    File: 1-discriminator.py\n",
    "    Code language: (project based)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fbe1a",
   "metadata": {},
   "source": [
    "### 2. Train Discriminator\n",
    "Write a function def train_discriminator(Z, X): that creates the loss tensor and training op for the discriminator:\n",
    "\n",
    "    Z is the tf.placeholder that is the input for the generator\n",
    "    X is the tf.placeholder that is the real input for the discriminator\n",
    "    You can use the following imports:\n",
    "        generator = __import__('0-generator').generator\n",
    "        discriminator = __import__('1-discriminator').discriminator\n",
    "    The discriminator should minimize the negative minimax loss\n",
    "    The discriminator should be trained using Adam optimization\n",
    "    The generator should NOT be trained\n",
    "    Returns: loss, train_op\n",
    "        loss is the discriminator loss\n",
    "        train_op is the training operation for the discriminator\n",
    "\n",
    "Repo:\n",
    "\n",
    "    GitHub repository: holbertonschool-machine_learning\n",
    "    Directory: unsupervised_learning/0x05-GANs\n",
    "    File: 2-train_discriminator.py\n",
    "    Code language: (project based)\n",
    "\n",
    "0 online checks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db141937",
   "metadata": {},
   "source": [
    "### 3. Train Generator \n",
    "Write a function def train_generator(Z): that creates the loss tensor and training op for the generator:\n",
    "\n",
    "    Z is the tf.placeholder that is the input for the generator\n",
    "    X is the tf.placeholder that is the input for the discriminator\n",
    "    You can use the following imports:\n",
    "        generator = __import__('0-generator').generator\n",
    "        discriminator = __import__('1-discriminator').discriminator\n",
    "    The generator should minimize the negative modified minimax loss\n",
    "    The generator should be trained using Adam optimization\n",
    "    The discriminator should NOT be trained\n",
    "    Returns: loss, train_op\n",
    "        loss is the generator loss\n",
    "        train_op is the training operation for the generator\n",
    "\n",
    "Repo:\n",
    "\n",
    "    GitHub repository: holbertonschool-machine_learning\n",
    "    Directory: unsupervised_learning/0x05-GANs\n",
    "    File: 3-train_generator.py\n",
    "    Code language: (project based)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa81558",
   "metadata": {},
   "source": [
    "### 5. Train GAN  \n",
    "Write a function def train_gan(X, epochs, batch_size, Z_dim, save_path='/tmp'): that trains a GAN:\n",
    "\n",
    "    X is a np.ndarray of shape (m, 784) containing the real data input\n",
    "        m is the number of real data samples\n",
    "    epochs is the number of epochs that the each network should be trained for\n",
    "    batch_size is the batch size that should be used during training\n",
    "    Z_dim is the number of dimensions for the randomly generated input\n",
    "    save_path is the path to save the trained generator\n",
    "        Create the tf.placeholder for Z and add it to the graphâ€™s collection\n",
    "    The discriminator and generator training should be altered after one epoch\n",
    "    You can use the following imports:\n",
    "        train_generator = __import__('2-train_generator').train_generator\n",
    "        train_discriminator = __import__('3-train_discriminator').train_discriminator\n",
    "        sample_Z = __import__('4-sample_Z').sample_Z\n",
    "\n",
    "Repo:\n",
    "\n",
    "    GitHub repository: holbertonschool-machine_learning\n",
    "    Directory: unsupervised_learning/0x05-GANs\n",
    "    File: 5-train_GAN.py\n",
    "    Code language: (project based)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33f4af",
   "metadata": {},
   "source": [
    "## SOMETHING\n",
    "\n",
    "Look at matrice using latex in jupyter:\n",
    "\n",
    "$$T^{\\mu\\nu}=\\begin{pmatrix}\n",
    "\\varepsilon&0&0&0\\\\\n",
    "0&\\varepsilon/3&0&0\\\\\n",
    "0&0&\\varepsilon/3&0\\\\\n",
    "0&0&0&\\varepsilon/3\n",
    "\\end{pmatrix},$$\n",
    "\n",
    "### Where can I use notebooks at?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a8c23",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Creswell, A., White, T., Dumoulin, V., Arulkumaran, K., Sengupta, B., & Bharath, A. A. (2018). Generative adversarial networks: An overview. IEEE Signal Processing Magazine, 35(1), 53-65.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb0726",
   "metadata": {},
   "source": [
    " ## Quiz questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5cc63",
   "metadata": {},
   "source": [
    "### Question #0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a769e",
   "metadata": {},
   "source": [
    "### Question #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4031e",
   "metadata": {},
   "source": [
    "### Question #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe068a",
   "metadata": {},
   "source": [
    "### Question #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36feaa",
   "metadata": {},
   "source": [
    "### Question #4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53977c96",
   "metadata": {},
   "source": [
    "### Question #5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fac584",
   "metadata": {},
   "source": [
    "## Errata \n",
    "*This section just contains information that I think I should look at again* \n",
    "* Add google colab links to notebook and microsoft learn too \n",
    "https://docs.microsoft.com/en-us/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800faa62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
